#!/usr/bin/env python3
"""
Runner r√°pido para tests de precisi√≥n (accuracy) de detecci√≥n de gestos.
Ejecuta un subconjunto optimizado de tests para validaci√≥n r√°pida.
"""

import sys
import os
import time
import unittest
from datetime import datetime
from typing import Dict, List, Any

# Agregar el directorio ra√≠z al path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../../')))

# Importar tests de accuracy
from tests.performance.metrics.accuracy.test_mouse_controller_accuracy import TestMouseControllerAccuracy
from tests.performance.metrics.accuracy.test_volume_controller_accuracy import TestVolumeControllerAccuracy
from tests.performance.metrics.accuracy.test_navigation_controller_accuracy import TestNavigationControllerAccuracy
from tests.performance.metrics.accuracy.test_system_controller_accuracy import TestSystemControllerAccuracy
from tests.performance.metrics.accuracy.test_shortcuts_controller_accuracy import TestShortcutsControllerAccuracy
from tests.performance.metrics.accuracy.test_multimedia_controller_accuracy import TestMultimediaControllerAccuracy
from tests.performance.metrics.accuracy.test_app_controller_accuracy import TestAppControllerAccuracy

class QuickAccuracyTestRunner:
    """Runner r√°pido para tests de precisi√≥n"""
    
    def __init__(self):
        # Tests priorizados por importancia y velocidad
        self.priority_controllers = [
            'mouse',        # Cr√≠tico para interacci√≥n
            'shortcuts',    # Cr√≠tico para productividad
            'volume',       # Usado frecuentemente
            'navigation',   # Usado frecuentemente
            'multimedia',   # Moderadamente usado
            'system',       # Cr√≠tico pero menos frecuente
            'app'          # Menos cr√≠tico
        ]
        
        # Mapeo de tests disponibles
        self.test_classes = {
            'mouse': TestMouseControllerAccuracy,
            'volume': TestVolumeControllerAccuracy,
            'navigation': TestNavigationControllerAccuracy,
            'system': TestSystemControllerAccuracy,
            'shortcuts': TestShortcutsControllerAccuracy,
            'multimedia': TestMultimediaControllerAccuracy,
            'app': TestAppControllerAccuracy
        }
        
        # Objetivos de precisi√≥n m√≠nima para test r√°pido
        self.min_accuracy_thresholds = {
            'mouse': 0.90,        # 90% m√≠nimo para mouse
            'shortcuts': 0.88,    # 88% m√≠nimo para atajos
            'volume': 0.85,       # 85% m√≠nimo para volumen
            'navigation': 0.83,   # 83% m√≠nimo para navegaci√≥n
            'multimedia': 0.80,   # 80% m√≠nimo para multimedia
            'system': 0.75,       # 75% m√≠nimo para sistema (m√°s conservador)
            'app': 0.72           # 72% m√≠nimo para apps
        }
        
        # Tests espec√≠ficos a ejecutar por controlador (subset r√°pido)
        self.quick_test_methods = {
            'mouse': ['test_basic_mouse_controls_accuracy', 'test_click_precision_accuracy'],
            'shortcuts': ['test_essential_shortcuts_accuracy', 'test_copy_paste_cut_discrimination'],
            'volume': ['test_basic_volume_controls_accuracy', 'test_volume_direction_discrimination'],
            'navigation': ['test_basic_navigation_accuracy', 'test_back_forward_discrimination'],
            'multimedia': ['test_basic_playback_controls_accuracy', 'test_play_pause_stop_discrimination'],
            'system': ['test_critical_operations_accuracy', 'test_shutdown_restart_discrimination'],
            'app': ['test_app_opening_accuracy', 'test_window_management_accuracy']
        }
    
    def run_quick_test(self, controller: str) -> Dict[str, Any]:
        """
        Ejecuta test r√°pido para un controlador espec√≠fico
        
        Args:
            controller: Nombre del controlador
            
        Returns:
            Dict con resultados del test r√°pido
        """
        if controller not in self.test_classes:
            raise ValueError(f"Controlador {controller} no disponible")
        
        print(f"\n‚ö° QUICK TEST: {controller.upper()}")
        print(f"{'‚îÄ' * 40}")
        
        test_class = self.test_classes[controller]
        test_methods = self.quick_test_methods.get(controller, [])
        min_threshold = self.min_accuracy_thresholds[controller]
        
        # Crear instancia de la clase de test
        test_instance = test_class()
        test_instance.setUp()
        
        results = {
            'controller': controller,
            'min_threshold': min_threshold,
            'tests_executed': [],
            'success_count': 0,
            'total_tests': len(test_methods),
            'execution_time': 0,
            'overall_status': 'PENDING'
        }
        
        start_time = time.time()
        
        try:
            # Ejecutar tests espec√≠ficos
            for method_name in test_methods:
                if hasattr(test_instance, method_name):
                    print(f"   üîç {method_name}...", end=' ')
                    
                    try:
                        method = getattr(test_instance, method_name)
                        method()
                        
                        results['tests_executed'].append({
                            'method': method_name,
                            'status': 'PASS',
                            'error': None
                        })
                        results['success_count'] += 1
                        print("‚úÖ")
                        
                    except Exception as e:
                        results['tests_executed'].append({
                            'method': method_name,
                            'status': 'FAIL',
                            'error': str(e)
                        })
                        print(f"‚ùå ({str(e)[:50]}...)")
                
                else:
                    print(f"   ‚ö†Ô∏è M√©todo {method_name} no encontrado")
            
            # Limpiar
            test_instance.tearDown()
            
        except Exception as e:
            print(f"   ‚ùå Error en setup/teardown: {e}")
        
        end_time = time.time()
        results['execution_time'] = end_time - start_time
        
        # Calcular tasa de √©xito
        success_rate = results['success_count'] / results['total_tests'] if results['total_tests'] > 0 else 0
        results['success_rate'] = success_rate
        
        # Determinar estado general
        if success_rate >= min_threshold:
            if success_rate >= 0.95:
                results['overall_status'] = '‚úÖ EXCELENTE'
            elif success_rate >= 0.85:
                results['overall_status'] = '‚úÖ BUENO'
            else:
                results['overall_status'] = '‚úÖ ACEPTABLE'
        else:
            results['overall_status'] = '‚ùå INSUFICIENTE'
        
        # Mostrar resumen
        print(f"   üìä √âxito: {results['success_count']}/{results['total_tests']} ({success_rate:.1%})")
        print(f"   ‚è±Ô∏è Tiempo: {results['execution_time']:.2f}s")
        print(f"   üéØ Estado: {results['overall_status']}")
        
        return results
    
    def run_all_quick_tests(self, max_controllers: int = None) -> Dict[str, Any]:
        """
        Ejecuta tests r√°pidos para m√∫ltiples controladores
        
        Args:
            max_controllers: N√∫mero m√°ximo de controladores a testear
            
        Returns:
            Dict con resultados de todos los tests
        """
        print("\n‚ö° QUICK ACCURACY TEST SUITE")
        print("=" * 50)
        print("üéØ Ejecutando subset optimizado de tests de precisi√≥n")
        
        start_time = time.time()
        all_results = {}
        
        # Determinar controladores a testear
        controllers_to_test = self.priority_controllers
        if max_controllers:
            controllers_to_test = controllers_to_test[:max_controllers]
        
        print(f"üìã Controladores a testear: {', '.join(controllers_to_test)}")
        
        # Ejecutar tests
        for i, controller in enumerate(controllers_to_test, 1):
            try:
                print(f"\n[{i}/{len(controllers_to_test)}] ", end='')
                result = self.run_quick_test(controller)
                all_results[controller] = result
                
            except Exception as e:
                print(f"‚ùå Error en {controller}: {e}")
                all_results[controller] = {
                    'controller': controller,
                    'error': str(e),
                    'overall_status': '‚ùå ERROR'
                }
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # Generar reporte r√°pido
        self.generate_quick_report(all_results, total_time)
        
        return all_results
    
    def generate_quick_report(self, results: Dict[str, Any], total_time: float):
        """
        Genera reporte r√°pido de los tests
        
        Args:
            results: Resultados de los tests
            total_time: Tiempo total de ejecuci√≥n
        """
        print(f"\n{'=' * 50}")
        print("üìä REPORTE R√ÅPIDO DE PRECISI√ìN")
        print(f"{'=' * 50}")
        
        print(f"‚è±Ô∏è Tiempo total: {total_time:.2f}s")
        print(f"üìÖ Ejecutado: {datetime.now().strftime('%H:%M:%S')}")
        
        # Estad√≠sticas r√°pidas
        total_tests = sum(r.get('total_tests', 0) for r in results.values() if 'total_tests' in r)
        total_success = sum(r.get('success_count', 0) for r in results.values() if 'success_count' in r)
        overall_rate = total_success / total_tests if total_tests > 0 else 0
        
        print(f"\nüìà RESULTADOS GLOBALES:")
        print(f"   üéØ Tests ejecutados: {total_tests}")
        print(f"   ‚úÖ Tasa de √©xito: {overall_rate:.1%}")
        
        # Resultados por controlador
        print(f"\nüèÜ RESULTADOS POR CONTROLADOR:")
        
        valid_results = [(name, data) for name, data in results.items() if 'success_rate' in data]
        
        for controller, data in valid_results:
            threshold = self.min_accuracy_thresholds.get(controller, 0.80)
            rate = data['success_rate']
            time_taken = data['execution_time']
            status = data['overall_status']
            
            threshold_met = "‚úÖ" if rate >= threshold else "‚ùå"
            
            print(f"   ‚Ä¢ {controller.upper():12} {rate:6.1%} ({time_taken:4.1f}s) {threshold_met} {status}")
        
        # Alertas
        failed_controllers = [
            name for name, data in valid_results 
            if data['success_rate'] < self.min_accuracy_thresholds.get(name, 0.80)
        ]
        
        if failed_controllers:
            print(f"\n‚ö†Ô∏è REQUIEREN ATENCI√ìN:")
            for controller in failed_controllers:
                data = results[controller]
                threshold = self.min_accuracy_thresholds[controller]
                gap = threshold - data['success_rate']
                print(f"   ‚Ä¢ {controller.upper()}: {data['success_rate']:.1%} (necesita +{gap:.1%})")
        
        # Estado general
        print(f"\nüéØ ESTADO GENERAL:")
        if overall_rate >= 0.90:
            print("   ‚úÖ Sistema con excelente precisi√≥n")
        elif overall_rate >= 0.80:
            print("   ‚úÖ Sistema con buena precisi√≥n")
        elif overall_rate >= 0.70:
            print("   ‚ö†Ô∏è Sistema con precisi√≥n aceptable")
        else:
            print("   ‚ùå Sistema requiere mejoras en precisi√≥n")
        
        print("=" * 50)
    
    def run_single_controller_deep_dive(self, controller: str):
        """
        Ejecuta test profundo para un controlador espec√≠fico
        
        Args:
            controller: Controlador a testear en profundidad
        """
        if controller not in self.test_classes:
            print(f"‚ùå Controlador '{controller}' no disponible")
            return
        
        print(f"\nüîç DEEP DIVE: {controller.upper()} CONTROLLER")
        print("=" * 60)
        
        test_class = self.test_classes[controller]
        
        # Ejecutar todos los tests del controlador
        suite = unittest.TestLoader().loadTestsFromTestCase(test_class)
        
        start_time = time.time()
        runner = unittest.TextTestRunner(verbosity=2)
        result = runner.run(suite)
        end_time = time.time()
        
        # Mostrar resumen detallado
        print(f"\nüìä RESUMEN DETALLADO {controller.upper()}:")
        print(f"   ‚úÖ Tests ejecutados: {result.testsRun}")
        print(f"   ‚ùå Fallos: {len(result.failures)}")
        print(f"   üêõ Errores: {len(result.errors)}")
        print(f"   ‚è±Ô∏è Tiempo: {end_time - start_time:.2f}s")
        
        success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun
        print(f"   üìà Tasa de √©xito: {success_rate:.1%}")


def main():
    """Funci√≥n principal"""
    runner = QuickAccuracyTestRunner()
    
    if len(sys.argv) > 1:
        arg = sys.argv[1]
        
        if arg == "all":
            # Todos los controladores
            runner.run_all_quick_tests()
        elif arg.startswith("top"):
            # Top N controladores
            try:
                n = int(arg[3:]) if len(arg) > 3 else 3
                runner.run_all_quick_tests(max_controllers=n)
            except ValueError:
                runner.run_all_quick_tests(max_controllers=3)
        elif arg in runner.test_classes:
            # Controlador espec√≠fico (deep dive)
            runner.run_single_controller_deep_dive(arg)
        else:
            # Lista de controladores
            controllers = arg.split(',')
            for controller in controllers:
                if controller in runner.test_classes:
                    runner.run_quick_test(controller)
                else:
                    print(f"‚ö†Ô∏è Controlador '{controller}' no disponible")
    else:
        # Test r√°pido por defecto (top 3)
        print("üöÄ Ejecutando quick test para controladores prioritarios")
        runner.run_all_quick_tests(max_controllers=3)


if __name__ == '__main__':
    main() 